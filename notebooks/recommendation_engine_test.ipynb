{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook implements an experiment aimed to verify accuracy of Deep Hybrid AutoencodeR Recommendation ENgine (DHARREN), on a dataset used in a [recent publication](https://github.com/MengtingWan/marketBias). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_qCk_TEjmvy"
   },
   "source": [
    "# Technical prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:50.407938Z",
     "start_time": "2020-01-27T13:23:48.664125Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "5vtoEr7MjlDC",
    "outputId": "eb220c76-817b-4c58-808b-10c7f759e036"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwojcik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.sparse import lil_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX9KBY4DjtUh"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:51.778037Z",
     "start_time": "2020-01-27T13:23:50.409816Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KQHy1rTakAjG"
   },
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/MengtingWan/marketBias/master/data/df_electronics.csv\"\n",
    "s=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.690841Z",
     "start_time": "2020-01-27T13:23:51.779731Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m86bBL2tjuD-"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.713923Z",
     "start_time": "2020-01-27T13:23:52.692697Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "UJah_fG6j2d6",
    "outputId": "b13ad305-17fa-4c28-e681-ee76ce194d85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>year</th>\n",
       "      <th>user_attr</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-13</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-14</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-06-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating   timestamp model_attr                category  \\\n",
       "0        0        0     5.0  1999-06-13     Female  Portable Audio & Video   \n",
       "1        0        1     5.0  1999-06-14     Female  Portable Audio & Video   \n",
       "2        0        2     3.0  1999-06-17     Female  Portable Audio & Video   \n",
       "\n",
       "  brand  year user_attr  split  \n",
       "0   NaN  1999       NaN      0  \n",
       "1   NaN  1999       NaN      0  \n",
       "2   NaN  1999       NaN      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.862190Z",
     "start_time": "2020-01-27T13:23:52.715482Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "e0DNYza4kQFf",
    "outputId": "6ff72324-75de-4ae3-d0d2-cccb18a73caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'HP', 'Philips', 'Polaroid', 'Panasonic', 'JVC', 'Fujifilm',\n",
       "       'Nikon', 'Kodak', 'Sony', 'Canon', 'Kensington', 'Pyle', 'Olympus',\n",
       "       'Toshiba', 'Logitech', 'Etre Jeune', 'Linksys', 'Vivitar',\n",
       "       'Sennheiser', 'Apple', 'Samsung', 'EldHus', 'Bose', 'Archos',\n",
       "       'Garmin', 'Jabra', 'Gary Fong', 'ViewSonic', 'Savage', 'Uniden',\n",
       "       'ebasy', 'Generic', 'JLAB', 'Skullcandy', 'TaoTronics', 'Neewer',\n",
       "       'Koolertron', 'DURAGADGET', 'iRULU', 'Tiamat', 'DBPOWER', 'Fintie',\n",
       "       'Plemo', 'EINCAR', 'Cooper Cases', 'LSS', 'Mpow', 'XShields',\n",
       "       'IRULU', 'Funlux'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.brand.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.124237Z",
     "start_time": "2020-01-27T13:23:52.863896Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mfcQfJpUVa24"
   },
   "outputs": [],
   "source": [
    "raw_data.model_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.user_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.brand.fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.171226Z",
     "start_time": "2020-01-27T13:23:53.125997Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6gUSmdkwnWZj",
    "outputId": "16cbe0bf-6324-4f97-cbce-6ec3b4a01895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_uid = raw_data.user_id.max()\n",
    "max_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQO6cg0eRVqs"
   },
   "source": [
    "Testing if data consist consecutive id numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.325963Z",
     "start_time": "2020-01-27T13:23:53.173413Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ui-wm_9Co_PF"
   },
   "outputs": [],
   "source": [
    "unique_uid = pd.Series(raw_data.user_id.unique())\n",
    "expected_ids = pd.Series(range(max_uid + 1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(unique_uid, expected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.420035Z",
     "start_time": "2020-01-27T13:23:53.327602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4z3Le9QuR0Fe"
   },
   "outputs": [],
   "source": [
    "max_item_id = raw_data.item_id.max()\n",
    "unique_iids = pd.Series(raw_data.item_id.unique())\n",
    "expected_item_ids = pd.Series(range(max_item_id+1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(expected_item_ids, unique_iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.525255Z",
     "start_time": "2020-01-27T13:23:53.421774Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = ['user_attr', 'model_attr', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:08.640612Z",
     "start_time": "2020-01-27T13:23:53.527464Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "c1sRoaKoVmLd"
   },
   "outputs": [],
   "source": [
    "encoded_data = pd.get_dummies(raw_data[feature_columns], sparse=True)\n",
    "encoded_data['user_id'] = raw_data.user_id.values\n",
    "encoded_data['item_id'] = raw_data.item_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.015107Z",
     "start_time": "2020-01-27T13:24:08.642892Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)\n",
    "encoded_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = encoded_data.drop(['user_id', 'item_id'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Recreate ratings matrix if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.018289Z",
     "start_time": "2020-01-27T13:24:12.016564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recreate_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.150610Z",
     "start_time": "2020-01-27T13:24:12.019492Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "hidden": true,
    "id": "4_daWuk3pGoq",
    "outputId": "f2aa30a1-2e66-4bca-b09c-5631149a577e"
   },
   "outputs": [],
   "source": [
    "if recreate_matrix:\n",
    "    user_item_matrix = lil_matrix((max_uid+1, max_item_id+1), dtype=np.int8)\n",
    "\n",
    "    for row_idx, row in raw_data.iterrows():\n",
    "        uidx = row['user_id']\n",
    "        iidx = row['item_id']\n",
    "        rating = row['rating']    \n",
    "        user_item_matrix[uidx, iidx] = rating\n",
    "        if row_idx % 100000 == 0:\n",
    "            print(f\"Processed: {row_idx / float(raw_data.shape[0])}%\")\n",
    "            \n",
    "    user_item_matrix = user_item_matrix.tocsr()\n",
    "    print(\"done\")\n",
    "    save_npz(\"../data/processed/ratings_sparse_mat.npz\", user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.386603Z",
     "start_time": "2020-01-27T13:24:12.152653Z"
    }
   },
   "outputs": [],
   "source": [
    "user_item_matrix = load_npz(\"../data/processed/ratings_sparse_mat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:48.458676Z",
     "start_time": "2020-01-27T13:24:48.456477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'user_id', 'rating', 'timestamp', 'model_attr', 'category',\n",
       "       'brand', 'year', 'user_attr', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_attr</th>\n",
       "      <th>model_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292949</th>\n",
       "      <td>1157628</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292950</th>\n",
       "      <td>1157629</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292951</th>\n",
       "      <td>1157630</td>\n",
       "      <td>missing</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292952</th>\n",
       "      <td>1157631</td>\n",
       "      <td>missing</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292953</th>\n",
       "      <td>1157632</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235082 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id user_attr model_attr\n",
       "0              0   missing     Female\n",
       "1              1   missing     Female\n",
       "2              2   missing     Female\n",
       "3              3   missing     Female\n",
       "4              4   missing     Female\n",
       "...          ...       ...        ...\n",
       "1292949  1157628   missing     Female\n",
       "1292950  1157629   missing     Female\n",
       "1292951  1157630   missing     Female\n",
       "1292952  1157631   missing       Male\n",
       "1292953  1157632    Female     Female\n",
       "\n",
       "[1235082 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_attr_combinations = raw_data[['user_id', \"user_attr\", \"model_attr\"]].drop_duplicates()\n",
    "user_attr_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_userids = raw_data.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_val_ids = train_test_split(unique_userids, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = raw_data.loc[raw_data.user_id.isin(train_ids)]\n",
    "X_test_val = raw_data.loc[raw_data.user_id.isin(test_val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, validation_ids = train_test_split(test_val_ids, test_size=0.5, random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_raw, X_val_raw = raw_data.loc[raw_data.user_id.isin(test_ids)], raw_data.loc[raw_data.user_id.isin(validation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(X_test.user_id.values).union(X_val.user_id.values).union(X_train.user_id) == set(raw_data.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_raw.shape[0] + X_test_raw.shape[0] + X_val_raw.shape[0] == raw_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_train = user_item_matrix[train_ids, :]\n",
    "Xf_train = features_matrix[train_ids, :]\n",
    "\n",
    "Xr_test = user_item_matrix[test_ids, :]\n",
    "Xf_test = features_matrix[test_ids, :]\n",
    "\n",
    "Xr_val = user_item_matrix[validation_ids, :]\n",
    "Xf_val = features_matrix[validation_ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Xr_train.shape[0] + Xr_test.shape[0] + Xr_val.shape[0] == user_item_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_ratings_features(ratings, features, mask, normalize=False, batch_size=64):\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            f = features[i * batch_size : upper]\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield [r, f], r\n",
    "            \n",
    "def generator_ratings(ratings,mask, normalize=False, batch_size=64):\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        print(\"shuffling the data\")\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield r, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:25:22.760943Z",
     "start_time": "2020-01-27T13:25:22.755561Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    y_true = y_true * mask\n",
    "    y_pred = y_pred * mask\n",
    "    diff = y_pred - y_true\n",
    "    sqdiff = diff * diff * mask\n",
    "    sse = tf.reduce_sum(tf.reduce_sum(sqdiff))\n",
    "    n = tf.reduce_sum(tf.reduce_sum(mask))\n",
    "    return sse / n\n",
    "\n",
    "def mspe_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    return mape(y_true * mask, y_pred * mask)\n",
    "\n",
    "def mae_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    #y_true = y_true * mask\n",
    "    #y_pred = y_pred * mask\n",
    "    mape = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mape(y_true * mask, y_pred * mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep collaborative filtering implementation can be inspired by the following tutorial:\n",
    "\n",
    "https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_collaborative_filtering(n_users, n_movies, n_factors):\n",
    "    user = tf.keras.layers.Input(shape=(1,))\n",
    "    u = tf.keras.layers.Embedding(n_users, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user)\n",
    "    u =  tf.keras.layers.Reshape((n_factors,))(u)\n",
    "    \n",
    "    movie =  tf.keras.layers.Input(shape=(1,))\n",
    "    m =  tf.keras.layers.Embedding(n_movies, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(movie)\n",
    "    m =  tf.keras.layers.Reshape((n_factors,))(m)\n",
    "    \n",
    "    x =  tf.keras.layers.Dot(axes=1)([u, m])\n",
    "    model =  tf.keras.models.Model(inputs=[user, movie], outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=[mse_masked], optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers = raw_data.user_id.nunique()\n",
    "nitems = raw_data.item_id.nunique()\n",
    "factors = 128\n",
    "cfi = build_collaborative_filtering(nusers, nitems, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 904732 samples, validate on 194282 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwojcik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:107: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 148177024 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-df7952fa19fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     validation_data=([X_val_raw.user_id.values, X_val_raw.item_id.values], X_val_raw.rating.values))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfi.fit(\n",
    "    x=[X_train_raw.user_id.values, X_train_raw.item_id.values], \n",
    "    y=X_train_raw.rating.values, \n",
    "    batch_size=32, \n",
    "    epochs=2, \n",
    "    verbose=1, \n",
    "    validation_data=([X_val_raw.user_id.values, X_val_raw.item_id.values], X_val_raw.rating.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildautorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc = tf.keras.layers.Dense(X_shape // 8, activation='relu')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop2)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:14:48.347321Z",
     "start_time": "2020-01-27T13:14:48.341707Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_deep_autorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc1)\n",
    "    enc2 = tf.keras.layers.Dense(X_shape // 8, activation='tanh')(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.2)(enc2)\n",
    "    dec1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.2)(dec1)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop4)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autorec_multi_input(X_shape, F_shape):\n",
    "    inp1 = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    inp2 = tf.keras.layers.Input(shape=(F_shape, ))\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    combined = concat([inp1, inp2])\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(combined)\n",
    "    enc1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc1)\n",
    "    enc2 = tf.keras.layers.Dense(X_shape // 8, activation='tanh')(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.2)(enc2)\n",
    "    dec1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.2)(dec1)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[inp1, inp2], outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T13:14:59.438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 9560)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 57)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 9617)         0           input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 9617)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2390)         22987020    dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 2390)         0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1195)         2857245     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1195)         0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2390)         2858440     dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 2390)         0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 9560)         22857960    dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 51,560,665\n",
      "Trainable params: 51,560,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "deepautorec = build_autorec_multi_input(user_item_matrix.shape[1], features_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (Xr_train > 0.0) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = user_item_matrix.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 18432/173645 [==>...........................] - ETA: 3:58 - loss: 25.4978 - mse_masked: 25.4978 - mspe_masked: 0.0135 - mae_masked: 4.7018e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-58990bcdb063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXr_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXf_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXr_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m           mode='test')\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1254\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_eval_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = deepautorec.fit_generator(\n",
    "    generator_ratings_features(Xr_train, Xf_train, train_mask, batch_size), \n",
    "    epochs=2,\n",
    "    steps_per_epoch=5,\n",
    "    validation_data=([Xr_val.toarray(), Xf_val], Xr_val.toarray())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [11.905031005859374, 19.175671463012694],\n",
       " 'mse_masked': [11.905032, 19.175665],\n",
       " 'mspe_masked': [0.009350273, 0.0119173955],\n",
       " 'mae_masked': [0.00034039113, 0.00043758715]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "recommendation_engine_test",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
