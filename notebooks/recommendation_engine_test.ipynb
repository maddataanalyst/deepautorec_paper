{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook implements an experiment aimed to verify accuracy of Deep Hybrid AutoencodeR Recommendation ENgine (DHARREN), on a dataset used in a [recent publication](https://github.com/MengtingWan/marketBias). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_qCk_TEjmvy"
   },
   "source": [
    "# Technical prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:50.407938Z",
     "start_time": "2020-01-27T13:23:48.664125Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "5vtoEr7MjlDC",
    "outputId": "eb220c76-817b-4c58-808b-10c7f759e036"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwojcik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.sparse import lil_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX9KBY4DjtUh"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:51.778037Z",
     "start_time": "2020-01-27T13:23:50.409816Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KQHy1rTakAjG"
   },
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/MengtingWan/marketBias/master/data/df_electronics.csv\"\n",
    "s=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.690841Z",
     "start_time": "2020-01-27T13:23:51.779731Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m86bBL2tjuD-"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.713923Z",
     "start_time": "2020-01-27T13:23:52.692697Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "UJah_fG6j2d6",
    "outputId": "b13ad305-17fa-4c28-e681-ee76ce194d85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>year</th>\n",
       "      <th>user_attr</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-13</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-14</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-06-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating   timestamp model_attr                category  \\\n",
       "0        0        0     5.0  1999-06-13     Female  Portable Audio & Video   \n",
       "1        0        1     5.0  1999-06-14     Female  Portable Audio & Video   \n",
       "2        0        2     3.0  1999-06-17     Female  Portable Audio & Video   \n",
       "\n",
       "  brand  year user_attr  split  \n",
       "0   NaN  1999       NaN      0  \n",
       "1   NaN  1999       NaN      0  \n",
       "2   NaN  1999       NaN      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:52.862190Z",
     "start_time": "2020-01-27T13:23:52.715482Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "e0DNYza4kQFf",
    "outputId": "6ff72324-75de-4ae3-d0d2-cccb18a73caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'HP', 'Philips', 'Polaroid', 'Panasonic', 'JVC', 'Fujifilm',\n",
       "       'Nikon', 'Kodak', 'Sony', 'Canon', 'Kensington', 'Pyle', 'Olympus',\n",
       "       'Toshiba', 'Logitech', 'Etre Jeune', 'Linksys', 'Vivitar',\n",
       "       'Sennheiser', 'Apple', 'Samsung', 'EldHus', 'Bose', 'Archos',\n",
       "       'Garmin', 'Jabra', 'Gary Fong', 'ViewSonic', 'Savage', 'Uniden',\n",
       "       'ebasy', 'Generic', 'JLAB', 'Skullcandy', 'TaoTronics', 'Neewer',\n",
       "       'Koolertron', 'DURAGADGET', 'iRULU', 'Tiamat', 'DBPOWER', 'Fintie',\n",
       "       'Plemo', 'EINCAR', 'Cooper Cases', 'LSS', 'Mpow', 'XShields',\n",
       "       'IRULU', 'Funlux'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.brand.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.124237Z",
     "start_time": "2020-01-27T13:23:52.863896Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mfcQfJpUVa24"
   },
   "outputs": [],
   "source": [
    "raw_data.model_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.user_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.brand.fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.171226Z",
     "start_time": "2020-01-27T13:23:53.125997Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6gUSmdkwnWZj",
    "outputId": "16cbe0bf-6324-4f97-cbce-6ec3b4a01895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_uid = raw_data.user_id.max()\n",
    "max_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQO6cg0eRVqs"
   },
   "source": [
    "Testing if data consist consecutive id numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.325963Z",
     "start_time": "2020-01-27T13:23:53.173413Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ui-wm_9Co_PF"
   },
   "outputs": [],
   "source": [
    "unique_uid = pd.Series(raw_data.user_id.unique())\n",
    "expected_ids = pd.Series(range(max_uid + 1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(unique_uid, expected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.420035Z",
     "start_time": "2020-01-27T13:23:53.327602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4z3Le9QuR0Fe"
   },
   "outputs": [],
   "source": [
    "max_item_id = raw_data.item_id.max()\n",
    "unique_iids = pd.Series(raw_data.item_id.unique())\n",
    "expected_item_ids = pd.Series(range(max_item_id+1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(expected_item_ids, unique_iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:23:53.525255Z",
     "start_time": "2020-01-27T13:23:53.421774Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = ['user_attr', 'model_attr', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:08.640612Z",
     "start_time": "2020-01-27T13:23:53.527464Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "c1sRoaKoVmLd"
   },
   "outputs": [],
   "source": [
    "encoded_data = pd.get_dummies(raw_data[feature_columns], sparse=True)\n",
    "encoded_data['user_id'] = raw_data.user_id.values\n",
    "encoded_data['item_id'] = raw_data.item_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.015107Z",
     "start_time": "2020-01-27T13:24:08.642892Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)\n",
    "encoded_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = encoded_data.drop(['user_id', 'item_id'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Recreate ratings matrix if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.018289Z",
     "start_time": "2020-01-27T13:24:12.016564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recreate_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.150610Z",
     "start_time": "2020-01-27T13:24:12.019492Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "hidden": true,
    "id": "4_daWuk3pGoq",
    "outputId": "f2aa30a1-2e66-4bca-b09c-5631149a577e"
   },
   "outputs": [],
   "source": [
    "if recreate_matrix:\n",
    "    user_item_matrix = lil_matrix((max_uid+1, max_item_id+1), dtype=np.int8)\n",
    "\n",
    "    for row_idx, row in raw_data.iterrows():\n",
    "        uidx = row['user_id']\n",
    "        iidx = row['item_id']\n",
    "        rating = row['rating']    \n",
    "        user_item_matrix[uidx, iidx] = rating\n",
    "        if row_idx % 100000 == 0:\n",
    "            print(f\"Processed: {row_idx / float(raw_data.shape[0])}%\")\n",
    "            \n",
    "    user_item_matrix = user_item_matrix.tocsr()\n",
    "    print(\"done\")\n",
    "    save_npz(\"../data/processed/ratings_sparse_mat.npz\", user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.386603Z",
     "start_time": "2020-01-27T13:24:12.152653Z"
    }
   },
   "outputs": [],
   "source": [
    "user_item_matrix = load_npz(\"../data/processed/ratings_sparse_mat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:48.458676Z",
     "start_time": "2020-01-27T13:24:48.456477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'user_id', 'rating', 'timestamp', 'model_attr', 'category',\n",
       "       'brand', 'year', 'user_attr', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(raw_data, stratify=raw_data.loc[:,[\"model_attr\", \"user_attr\"]], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_ratings_features(ratings, features, mask, normalize=False, batch_size=64):\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            f = features[i * batch_size : upper]\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield [r, f], r\n",
    "            \n",
    "def generator_ratings(ratings,mask, normalize=False, batch_size=64):\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        print(\"shuffling the data\")\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield r, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:25:22.760943Z",
     "start_time": "2020-01-27T13:25:22.755561Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    y_true = y_true * mask\n",
    "    y_pred = y_pred * mask\n",
    "    diff = y_pred - y_true\n",
    "    sqdiff = diff * diff * mask\n",
    "    sse = tf.reduce_sum(tf.reduce_sum(sqdiff))\n",
    "    n = tf.reduce_sum(tf.reduce_sum(mask))\n",
    "    return sse / n\n",
    "\n",
    "def mspe_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    return mape(y_true * mask, y_pred * mask)\n",
    "\n",
    "def mae_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    #y_true = y_true * mask\n",
    "    #y_pred = y_pred * mask\n",
    "    mape = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mape(y_true * mask, y_pred * mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep collaborative filtering implementation can be inspired by the following tutorial:\n",
    "\n",
    "https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_collaborative_filtering(n_users, n_movies, n_factors):\n",
    "    user = tf.keras.layers.Input(shape=(1,))\n",
    "    u = tf.keras.layers.Embedding(n_users, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user)\n",
    "    u =  tf.keras.layers.Reshape((n_factors,))(u)\n",
    "    \n",
    "    movie =  tf.keras.layers.Input(shape=(1,))\n",
    "    m =  tf.keras.layers.Embedding(n_movies, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(movie)\n",
    "    m =  tf.keras.layers.Reshape((n_factors,))(m)\n",
    "    \n",
    "    x =  tf.keras.layers.Dot(axes=1)([u, m])\n",
    "    model =  tf.keras.models.Model(inputs=[user, movie], outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=[mse_masked], optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers = raw_data.user_id.nunique()\n",
    "nitems = raw_data.item_id.nunique()\n",
    "factors = 128\n",
    "cfi = build_collaborative_filtering(nusers, nitems, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (user_item_matrix > 0.0) * 1.0\n",
    "batch_size = 64\n",
    "steps_per_epoch = user_item_matrix.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = deepautorec.fit_generator(generator_ratings_features(user_item_matrix, features_matrix, train_mask, batch_size), epochs=2, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildautorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc = tf.keras.layers.Dense(X_shape // 8, activation='relu')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop2)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:14:48.347321Z",
     "start_time": "2020-01-27T13:14:48.341707Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_deep_autorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc1)\n",
    "    enc2 = tf.keras.layers.Dense(X_shape // 8, activation='tanh')(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.2)(enc2)\n",
    "    dec1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.2)(dec1)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop4)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autorec_multi_input(X_shape, F_shape):\n",
    "    inp1 = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    inp2 = tf.keras.layers.Input(shape=(F_shape, ))\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    combined = concat([inp1, inp2])\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(combined)\n",
    "    enc1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc1)\n",
    "    enc2 = tf.keras.layers.Dense(X_shape // 8, activation='tanh')(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.2)(enc2)\n",
    "    dec1 = tf.keras.layers.Dense(X_shape // 4, activation='tanh')(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.2)(dec1)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[inp1, inp2], outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mspe_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-27T13:14:59.438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 9560)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 57)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 9617)         0           input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 9617)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2390)         22987020    dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 2390)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1195)         2857245     dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1195)         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2390)         2858440     dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 2390)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 9560)         22857960    dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 51,560,665\n",
      "Trainable params: 51,560,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "deepautorec = build_autorec_multi_input(user_item_matrix.shape[1], features_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (user_item_matrix > 0.0) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = user_item_matrix.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "474/500 [===========================>..] - ETA: 19s - loss: 14.5884 - mse_masked: 14.5884 - mspe_masked: 0.0106 - mae_masked: 3.7784e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-6b58f5fb5adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepautorec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_ratings_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = deepautorec.fit_generator(generator_ratings_features(user_item_matrix, features_matrix, train_mask, batch_size), epochs=2, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [11.905031005859374, 19.175671463012694],\n",
       " 'mse_masked': [11.905032, 19.175665],\n",
       " 'mspe_masked': [0.009350273, 0.0119173955],\n",
       " 'mae_masked': [0.00034039113, 0.00043758715]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "recommendation_engine_test",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
