{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook implements an experiment aimed to verify accuracy of Deep Hybrid AutoencodeR Recommendation ENgine (DHARREN), on a dataset used in a [recent publication](https://github.com/MengtingWan/marketBias). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_qCk_TEjmvy"
   },
   "source": [
    "# Technical prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:56:35.467647Z",
     "start_time": "2020-01-29T09:56:35.462618Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "5vtoEr7MjlDC",
    "outputId": "eb220c76-817b-4c58-808b-10c7f759e036"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import lil_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:55:24.471444Z",
     "start_time": "2020-01-29T09:55:24.296123Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX9KBY4DjtUh"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:11.589300Z",
     "start_time": "2020-01-29T09:40:05.355483Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KQHy1rTakAjG"
   },
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/MengtingWan/marketBias/master/data/df_electronics.csv\"\n",
    "s=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:14.169574Z",
     "start_time": "2020-01-29T09:40:13.234231Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m86bBL2tjuD-"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:17.018228Z",
     "start_time": "2020-01-29T09:40:15.845003Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "UJah_fG6j2d6",
    "outputId": "b13ad305-17fa-4c28-e681-ee76ce194d85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>year</th>\n",
       "      <th>user_attr</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-13</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-14</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-06-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating   timestamp model_attr                category  \\\n",
       "0        0        0     5.0  1999-06-13     Female  Portable Audio & Video   \n",
       "1        0        1     5.0  1999-06-14     Female  Portable Audio & Video   \n",
       "2        0        2     3.0  1999-06-17     Female  Portable Audio & Video   \n",
       "\n",
       "  brand  year user_attr  split  \n",
       "0   NaN  1999       NaN      0  \n",
       "1   NaN  1999       NaN      0  \n",
       "2   NaN  1999       NaN      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:18.749559Z",
     "start_time": "2020-01-29T09:40:18.707783Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "e0DNYza4kQFf",
    "outputId": "6ff72324-75de-4ae3-d0d2-cccb18a73caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'HP', 'Philips', 'Polaroid', 'Panasonic', 'JVC', 'Fujifilm',\n",
       "       'Nikon', 'Kodak', 'Sony', 'Canon', 'Kensington', 'Pyle', 'Olympus',\n",
       "       'Toshiba', 'Logitech', 'Etre Jeune', 'Linksys', 'Vivitar',\n",
       "       'Sennheiser', 'Apple', 'Samsung', 'EldHus', 'Bose', 'Archos',\n",
       "       'Garmin', 'Jabra', 'Gary Fong', 'ViewSonic', 'Savage', 'Uniden',\n",
       "       'ebasy', 'Generic', 'JLAB', 'Skullcandy', 'TaoTronics', 'Neewer',\n",
       "       'Koolertron', 'DURAGADGET', 'iRULU', 'Tiamat', 'DBPOWER', 'Fintie',\n",
       "       'Plemo', 'EINCAR', 'Cooper Cases', 'LSS', 'Mpow', 'XShields',\n",
       "       'IRULU', 'Funlux'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.brand.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:20.563211Z",
     "start_time": "2020-01-29T09:40:20.435774Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mfcQfJpUVa24"
   },
   "outputs": [],
   "source": [
    "raw_data.model_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.user_attr.fillna(\"missing\", inplace=True)\n",
    "raw_data.brand.fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:22.221711Z",
     "start_time": "2020-01-29T09:40:22.217160Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6gUSmdkwnWZj",
    "outputId": "16cbe0bf-6324-4f97-cbce-6ec3b4a01895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157632"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_uid = raw_data.user_id.max()\n",
    "max_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQO6cg0eRVqs"
   },
   "source": [
    "Testing if data consist consecutive id numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:23.929216Z",
     "start_time": "2020-01-29T09:40:23.897561Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ui-wm_9Co_PF"
   },
   "outputs": [],
   "source": [
    "unique_uid = pd.Series(raw_data.user_id.unique())\n",
    "expected_ids = pd.Series(range(max_uid + 1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(unique_uid, expected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:25.631719Z",
     "start_time": "2020-01-29T09:40:25.620746Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4z3Le9QuR0Fe"
   },
   "outputs": [],
   "source": [
    "max_item_id = raw_data.item_id.max()\n",
    "unique_iids = pd.Series(raw_data.item_id.unique())\n",
    "expected_item_ids = pd.Series(range(max_item_id+1))\n",
    "\n",
    "pd.util.testing.assert_series_equal(expected_item_ids, unique_iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:27.344139Z",
     "start_time": "2020-01-29T09:40:27.342322Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = ['user_attr', 'model_attr', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:41.911967Z",
     "start_time": "2020-01-29T09:40:29.038274Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "c1sRoaKoVmLd"
   },
   "outputs": [],
   "source": [
    "encoded_data = pd.get_dummies(raw_data[feature_columns], sparse=True)\n",
    "encoded_data['user_id'] = raw_data.user_id.values\n",
    "encoded_data['item_id'] = raw_data.item_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:47.307094Z",
     "start_time": "2020-01-29T09:40:43.931006Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)\n",
    "encoded_data.sort_values(by=['user_id', 'item_id'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:49.465861Z",
     "start_time": "2020-01-29T09:40:49.291629Z"
    }
   },
   "outputs": [],
   "source": [
    "features_matrix = encoded_data.drop(['user_id', 'item_id'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Recreate ratings matrix if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.018289Z",
     "start_time": "2020-01-27T13:24:12.016564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recreate_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T13:24:12.150610Z",
     "start_time": "2020-01-27T13:24:12.019492Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "hidden": true,
    "id": "4_daWuk3pGoq",
    "outputId": "f2aa30a1-2e66-4bca-b09c-5631149a577e"
   },
   "outputs": [],
   "source": [
    "if recreate_matrix:\n",
    "    user_item_matrix = lil_matrix((max_uid+1, max_item_id+1), dtype=np.int8)\n",
    "\n",
    "    for row_idx, row in raw_data.iterrows():\n",
    "        uidx = row['user_id']\n",
    "        iidx = row['item_id']\n",
    "        rating = row['rating']    \n",
    "        user_item_matrix[uidx, iidx] = rating\n",
    "        if row_idx % 100000 == 0:\n",
    "            print(f\"Processed: {row_idx / float(raw_data.shape[0])}%\")\n",
    "            \n",
    "    user_item_matrix = user_item_matrix.tocsr()\n",
    "    print(\"done\")\n",
    "    save_npz(\"../data/processed/ratings_sparse_mat.npz\", user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:40:54.994407Z",
     "start_time": "2020-01-29T09:40:51.439460Z"
    }
   },
   "outputs": [],
   "source": [
    "user_item_matrix = load_npz(\"../data/processed/ratings_sparse_mat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:05.119912Z",
     "start_time": "2020-01-29T09:41:05.116602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:07.148138Z",
     "start_time": "2020-01-29T09:41:07.142978Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_test_ratings_for_prediction(Xr_test, perc_test=0.2, min_ratings=3, random_state=999):\n",
    "    Xr_test_pred_hidden = Xr_test.copy()\n",
    "    perc_test = 0.1\n",
    "    row_nonzero, col_nonzero = Xr_test.nonzero()\n",
    "    nonzero_coords = dict(zip(row_nonzero, col_nonzero))\n",
    "    rating_counts = pd.value_counts(row_nonzero).reset_index().rename(columns={'index': 'uid', 0: 'cnt'})\n",
    "    user_ids = rating_counts.uid[rating_counts.cnt > min_ratings]\n",
    "    to_choose = int(len(user_ids) * perc_test)\n",
    "    selected_uids = np.random.choice(user_ids, size=to_choose)\n",
    "\n",
    "    uids = []\n",
    "    item_ids = []\n",
    "    y = []\n",
    "    for uid in selected_uids:\n",
    "        _, user_item_ids = Xr_test[uid, :].nonzero()\n",
    "        item_id = np.random.choice(user_item_ids, size=1)\n",
    "        uids.append(uid)\n",
    "        item_ids.append(item_id[0])\n",
    "        rating = Xr_test[uid, item_id].toarray().flatten()[0]\n",
    "        y.append(rating)\n",
    "        Xr_test_pred_hidden[uid, item_id] = 0\n",
    "        \n",
    "    return uids, item_ids, y, Xr_test_pred_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:09.138692Z",
     "start_time": "2020-01-29T09:41:09.136078Z"
    }
   },
   "outputs": [],
   "source": [
    "min_ratings_per_user = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:39:54.668854Z",
     "start_time": "2020-01-29T09:39:54.652984Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-230c481324b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:11.215658Z",
     "start_time": "2020-01-29T09:41:11.138462Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ids_ratings_cnt = pd.value_counts(raw_data.user_id).reset_index().rename(columns={'index': 'uid', 'user_id': 'cnt'})\n",
    "user_ids_min_ratings = user_ids_ratings_cnt.uid[user_ids_ratings_cnt.cnt >= min_ratings_per_user]\n",
    "unique_user_ids_min_ratings = user_ids_min_ratings.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:13.233565Z",
     "start_time": "2020-01-29T09:41:13.230041Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids, test_val_ids = train_test_split(unique_user_ids_min_ratings, test_size=0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:15.352059Z",
     "start_time": "2020-01-29T09:41:15.248345Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_raw = raw_data.loc[raw_data.user_id.isin(train_ids)]\n",
    "X_test_val = raw_data.loc[raw_data.user_id.isin(test_val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:17.415208Z",
     "start_time": "2020-01-29T09:41:17.411632Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ids, validation_ids = train_test_split(test_val_ids, test_size=0.5, random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:19.598767Z",
     "start_time": "2020-01-29T09:41:19.501048Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_raw, X_val_raw = raw_data.loc[raw_data.user_id.isin(test_ids)], raw_data.loc[raw_data.user_id.isin(validation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:21.852060Z",
     "start_time": "2020-01-29T09:41:21.769246Z"
    }
   },
   "outputs": [],
   "source": [
    "assert set(X_test_raw.user_id.values).union(X_val_raw.user_id.values).union(X_train_raw.user_id) == set(raw_data.loc[raw_data.user_id.isin(unique_user_ids_min_ratings)].user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:24.096407Z",
     "start_time": "2020-01-29T09:41:24.033122Z"
    }
   },
   "outputs": [],
   "source": [
    "assert X_train_raw.shape[0] + X_test_raw.shape[0] + X_val_raw.shape[0] == raw_data.loc[raw_data.user_id.isin(unique_user_ids_min_ratings)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:26.299496Z",
     "start_time": "2020-01-29T09:41:26.283463Z"
    }
   },
   "outputs": [],
   "source": [
    "Xr_train = user_item_matrix[train_ids, :]\n",
    "Xf_train = features_matrix[train_ids, :]\n",
    "\n",
    "Xr_test = user_item_matrix[test_ids, :]\n",
    "Xf_test = features_matrix[test_ids, :]\n",
    "\n",
    "Xr_val = user_item_matrix[validation_ids, :]\n",
    "Xf_val = features_matrix[validation_ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:28.497912Z",
     "start_time": "2020-01-29T09:41:28.492799Z"
    }
   },
   "outputs": [],
   "source": [
    "assert Xr_train.shape[0] + Xr_test.shape[0] + Xr_val.shape[0] == user_item_matrix[unique_user_ids_min_ratings, :].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:30.763484Z",
     "start_time": "2020-01-29T09:41:30.687076Z"
    }
   },
   "outputs": [],
   "source": [
    "test_uids, test_item_ids, test_y, Xr_test_pred_hidden = prepare_test_ratings_for_prediction(Xr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:32.950445Z",
     "start_time": "2020-01-29T09:41:32.945329Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_ratings_features(ratings, features, normalize=False, batch_size=64):\n",
    "    mask = (ratings > 0.0) * 1.0\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            f = features[i * batch_size : upper]\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield [r, f], r\n",
    "            \n",
    "def generator_ratings(ratings, normalize=False, batch_size=64):\n",
    "    mask = (ratings > 0.0) * 1.0\n",
    "    while True:\n",
    "        ratings, mask = shuffle(ratings, mask)\n",
    "        print(\"shuffling the data\")\n",
    "        for i in range(ratings.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1)*batch_size, ratings.shape[0])\n",
    "            r = ratings[i*batch_size:upper].toarray()\n",
    "            m = mask[i*batch_size:upper].toarray()\n",
    "            if normalize:\n",
    "                #r = r - mu * m\n",
    "                r = r * m\n",
    "            yield r, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:41:40.914928Z",
     "start_time": "2020-01-29T09:41:35.203559Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    y_true = y_true * mask\n",
    "    y_pred = y_pred * mask\n",
    "    diff = y_pred - y_true\n",
    "    sqdiff = diff * diff * mask\n",
    "    sse = tf.reduce_sum(tf.reduce_sum(sqdiff))\n",
    "    n = tf.reduce_sum(tf.reduce_sum(mask))\n",
    "    return sse / n\n",
    "\n",
    "def mape_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    \n",
    "    y_true = y_true * mask\n",
    "    y_pred = y_pred * mask\n",
    "    \n",
    "    return tf.reduce_mean( (y_true[y_true > 0.0] - y_pred[y_true > 0.0])/y_true[y_true > 0.0] )\n",
    "\n",
    "def mae_masked(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype='float32')\n",
    "    #y_true = y_true + mu * mask\n",
    "    #y_pred = y_pred + mu * mask\n",
    "    #y_true = y_true * mask\n",
    "    #y_pred = y_pred * mask\n",
    "    mape = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mape(y_true * mask, y_pred * mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep collaborative filtering implementation can be inspired by the following tutorial:\n",
    "\n",
    "https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:39:38.226819Z",
     "start_time": "2020-01-29T09:39:38.219791Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_collaborative_filtering(n_users, n_movies, n_factors):\n",
    "    user = tf.keras.layers.Input(shape=(1,))\n",
    "    u = tf.keras.layers.Embedding(n_users, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user)\n",
    "    u =  tf.keras.layers.Reshape((n_factors,))(u)\n",
    "    \n",
    "    movie =  tf.keras.layers.Input(shape=(1,))\n",
    "    m =  tf.keras.layers.Embedding(n_movies, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(movie)\n",
    "    m =  tf.keras.layers.Reshape((n_factors,))(m)\n",
    "    \n",
    "    x =  tf.keras.layers.Dot(axes=1)([u, m])\n",
    "    model =  tf.keras.models.Model(inputs=[user, movie], outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=[mse_masked], optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T08:57:28.650975Z",
     "start_time": "2020-01-29T08:57:28.590994Z"
    }
   },
   "outputs": [],
   "source": [
    "nusers = len(unique_user_ids_min_ratings)\n",
    "nitems = raw_data.item_id.nunique()\n",
    "factors = 128\n",
    "cfi = build_collaborative_filtering(nusers, nitems, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T08:57:30.465462Z",
     "start_time": "2020-01-29T08:57:29.956127Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43913 samples, validate on 14648 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fwojcik/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/fwojcik/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   32/43913 [..............................] - ETA: 9:46"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[0,0] = 130368 is not in [0, 20335)\n\t [[node model_34/embedding_6/embedding_lookup (defined at <ipython-input-326-df7952fa19fc>:7) ]]\n  (1) Invalid argument:  indices[0,0] = 130368 is not in [0, 20335)\n\t [[node model_34/embedding_6/embedding_lookup (defined at <ipython-input-326-df7952fa19fc>:7) ]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Adam/Const/_47]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_610221]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_34/embedding_6/embedding_lookup:\n model_34/embedding_6/embedding_lookup/609947 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node model_34/embedding_6/embedding_lookup:\n model_34/embedding_6/embedding_lookup/609947 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-df7952fa19fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     validation_data=([X_val_raw.user_id.values, X_val_raw.item_id.values], X_val_raw.rating.values))\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.virtualenvs/jupyterenvf/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[0,0] = 130368 is not in [0, 20335)\n\t [[node model_34/embedding_6/embedding_lookup (defined at <ipython-input-326-df7952fa19fc>:7) ]]\n  (1) Invalid argument:  indices[0,0] = 130368 is not in [0, 20335)\n\t [[node model_34/embedding_6/embedding_lookup (defined at <ipython-input-326-df7952fa19fc>:7) ]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Adam/Const/_47]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_610221]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_34/embedding_6/embedding_lookup:\n model_34/embedding_6/embedding_lookup/609947 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node model_34/embedding_6/embedding_lookup:\n model_34/embedding_6/embedding_lookup/609947 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "cfi.fit(\n",
    "    x=[X_train_raw.user_id.values, X_train_raw.item_id.values], \n",
    "    y=X_train_raw.rating.values, \n",
    "    batch_size=32, \n",
    "    epochs=2, \n",
    "    verbose=1, \n",
    "    validation_data=([X_val_raw.user_id.values, X_val_raw.item_id.values], X_val_raw.rating.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallow single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:00:04.747097Z",
     "start_time": "2020-01-29T10:00:04.742663Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_shallow_autorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc = tf.keras.layers.Dense(X_shape // 8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop2)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mape_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T09:42:09.997103Z",
     "start_time": "2020-01-29T09:42:09.991848Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_deep_autorec_single_input(X_shape):\n",
    "    inp = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.2)(inp)\n",
    "    enc1 = tf.keras.layers.Dense(X_shape // 4, activation='relu')(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.2)(enc1)\n",
    "    enc2 = tf.keras.layers.Dense(X_shape // 8, activation='relu')(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.2)(enc2)\n",
    "    dec1 = tf.keras.layers.Dense(X_shape // 4, activation='relu')(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.2)(dec1)\n",
    "    out = tf.keras.layers.Dense(X_shape, activation='relu')(drop4)\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mape_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:01:54.803412Z",
     "start_time": "2020-01-29T10:01:54.794558Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_autorec_multi_input(X_shape, F_shape):  \n",
    "    inp1 = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    inp2 = tf.keras.layers.Input(shape=(F_shape, ))\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    combined = concat([inp1, inp2])\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.1)(combined)\n",
    "    #bnorm = tf.keras.layers.BatchNormalization()(drop1)\n",
    "    enc = tf.keras.layers.Dense(\n",
    "        X_shape // 4, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop1)\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.1)(enc)\n",
    "    out = tf.keras.layers.Dense(\n",
    "        X_shape,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop2)\n",
    "    model = tf.keras.models.Model(inputs=[inp1, inp2], outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mape_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:24:19.585632Z",
     "start_time": "2020-01-29T10:24:19.574867Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_autorec_multi_input2(X_shape, F_shape):  \n",
    "    inp1 = tf.keras.layers.Input(shape=(X_shape, ))\n",
    "    inp2 = tf.keras.layers.Input(shape=(F_shape, ))\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    drop1 = tf.keras.layers.Dropout(rate=0.1)(inp1)\n",
    "    #bnorm = tf.keras.layers.BatchNormalization()(drop1)\n",
    "    enc = tf.keras.layers.Dense(\n",
    "        X_shape // 4, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop1)\n",
    "    combined = concat([enc, inp2])\n",
    "    drop2 = tf.keras.layers.Dropout(rate=0.3)(combined)\n",
    "    enc2 = tf.keras.layers.Dense(\n",
    "        X_shape // 16, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop2)\n",
    "    drop3 = tf.keras.layers.Dropout(rate=0.3)(enc2)\n",
    "    dec =  tf.keras.layers.Dense(\n",
    "        X_shape // 4, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop3)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.3)(dec)\n",
    "    out = tf.keras.layers.Dense(\n",
    "        X_shape,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop4)\n",
    "    model = tf.keras.models.Model(inputs=[inp1, inp2], outputs=out)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "    model.compile(optimizer=optimizer, loss=[mse_masked], metrics=[mse_masked, mape_masked, mae_masked])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:00:28.671444Z",
     "start_time": "2020-01-29T10:00:08.025273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 9560)]            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 9560)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1195)              11425395  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1195)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9560)              11433760  \n",
      "=================================================================\n",
      "Total params: 22,859,155\n",
      "Trainable params: 22,859,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shuffling the data\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 190 steps, validate on 4067 samples\n",
      "Epoch 1/10\n",
      "155/190 [=======================>......] - ETA: 0s - loss: 10.0968 - mse_masked: 9.3053 - mape_masked: 0.4109 - mae_masked: 9.5933e-04shuffling the data\n",
      "190/190 [==============================] - 3s 14ms/step - loss: 9.2637 - mse_masked: 8.4106 - mape_masked: 0.3532 - mae_masked: 8.9582e-04 - val_loss: 5.5875 - val_mse_masked: 4.3859 - val_mape_masked: 0.0628 - val_mae_masked: 5.8414e-04\n",
      "Epoch 2/10\n",
      "157/190 [=======================>......] - ETA: 0s - loss: 4.4040 - mse_masked: 3.0970 - mape_masked: 0.0064 - mae_masked: 5.0512e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 4.3870 - mse_masked: 3.0627 - mape_masked: 5.1310e-04 - mae_masked: 5.0224e-04 - val_loss: 4.4211 - val_mse_masked: 2.9900 - val_mape_masked: -0.0028 - val_mae_masked: 4.8192e-04\n",
      "Epoch 3/10\n",
      "157/190 [=======================>......] - ETA: 0s - loss: 3.5167 - mse_masked: 2.0874 - mape_masked: -0.0520 - mae_masked: 4.1739e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.5368 - mse_masked: 2.0994 - mape_masked: -0.0527 - mae_masked: 4.1832e-04 - val_loss: 4.1589 - val_mse_masked: 2.6689 - val_mape_masked: -0.0587 - val_mae_masked: 4.4998e-04\n",
      "Epoch 4/10\n",
      "157/190 [=======================>......] - ETA: 0s - loss: 3.3438 - mse_masked: 1.8946 - mape_masked: -0.0654 - mae_masked: 3.9499e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.3691 - mse_masked: 1.9151 - mape_masked: -0.0670 - mae_masked: 3.9659e-04 - val_loss: 4.2161 - val_mse_masked: 2.7206 - val_mape_masked: -0.0522 - val_mae_masked: 4.5323e-04\n",
      "Epoch 5/10\n",
      "157/190 [=======================>......] - ETA: 0s - loss: 3.2536 - mse_masked: 1.7966 - mape_masked: -0.0680 - mae_masked: 3.8225e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.2760 - mse_masked: 1.8112 - mape_masked: -0.0665 - mae_masked: 3.8389e-04 - val_loss: 4.2115 - val_mse_masked: 2.6864 - val_mape_masked: -0.0562 - val_mae_masked: 4.5090e-04\n",
      "Epoch 6/10\n",
      "163/190 [========================>.....] - ETA: 0s - loss: 3.2838 - mse_masked: 1.7909 - mape_masked: -0.0628 - mae_masked: 3.8495e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.2999 - mse_masked: 1.8001 - mape_masked: -0.0620 - mae_masked: 3.8479e-04 - val_loss: 4.2838 - val_mse_masked: 2.7294 - val_mape_masked: -0.0397 - val_mae_masked: 4.5588e-04\n",
      "Epoch 7/10\n",
      "163/190 [========================>.....] - ETA: 0s - loss: 3.2489 - mse_masked: 1.7341 - mape_masked: -0.0575 - mae_masked: 3.7623e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.2765 - mse_masked: 1.7542 - mape_masked: -0.0602 - mae_masked: 3.7819e-04 - val_loss: 4.2736 - val_mse_masked: 2.6955 - val_mape_masked: -0.0491 - val_mae_masked: 4.5290e-04\n",
      "Epoch 8/10\n",
      "163/190 [========================>.....] - ETA: 0s - loss: 3.2525 - mse_masked: 1.7114 - mape_masked: -0.0586 - mae_masked: 3.7057e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.2855 - mse_masked: 1.7421 - mape_masked: -0.0577 - mae_masked: 3.7429e-04 - val_loss: 4.3075 - val_mse_masked: 2.7240 - val_mape_masked: -0.0390 - val_mae_masked: 4.5761e-04\n",
      "Epoch 9/10\n",
      "163/190 [========================>.....] - ETA: 0s - loss: 3.2955 - mse_masked: 1.7359 - mape_masked: -0.0547 - mae_masked: 3.7151e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.3173 - mse_masked: 1.7538 - mape_masked: -0.0571 - mae_masked: 3.7530e-04 - val_loss: 4.2778 - val_mse_masked: 2.6759 - val_mape_masked: -0.0335 - val_mae_masked: 4.5518e-04\n",
      "Epoch 10/10\n",
      "163/190 [========================>.....] - ETA: 0s - loss: 3.2104 - mse_masked: 1.6532 - mape_masked: -0.0535 - mae_masked: 3.6581e-04shuffling the data\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 3.2519 - mse_masked: 1.6923 - mape_masked: -0.0528 - mae_masked: 3.7137e-04 - val_loss: 4.3505 - val_mse_masked: 2.7510 - val_mape_masked: -0.0468 - val_mae_masked: 4.5966e-04\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = Xr_train.shape[0] // batch_size\n",
    "\n",
    "shallow_autorec = build_shallow_autorec_single_input(user_item_matrix.shape[1])\n",
    "results_autorec_simple = shallow_autorec.fit_generator(\n",
    "    generator_ratings(Xr_train, batch_size), \n",
    "    epochs=10,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(Xr_val.toarray().astype(np.float32), Xr_val.toarray().astype(np.float32))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:01:01.777116Z",
     "start_time": "2020-01-29T10:01:01.465833Z"
    }
   },
   "outputs": [],
   "source": [
    "Xr_test_reconstruction_shallow = shallow_autorec.predict(Xr_test_pred_hidden.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:01:04.240684Z",
     "start_time": "2020-01-29T10:01:04.067812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.7479384>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_masked(Xr_test_pred_hidden.toarray(), Xr_test_reconstruction_shallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:01:06.535765Z",
     "start_time": "2020-01-29T10:01:06.533089Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat = []\n",
    "for test_uid, test_itemid in zip(test_uids, test_item_ids):\n",
    "    yhat.append(Xr_test_reconstruction_shallow[test_uid, test_itemid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:01:08.848710Z",
     "start_time": "2020-01-29T10:01:08.837277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2167392, -0.015748145, 1.4263917)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_masked(test_y, yhat).numpy(), mape_masked(test_y, yhat).numpy(), mae_masked(test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multi input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:25:43.821573Z",
     "start_time": "2020-01-29T10:25:05.509708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 9560)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 9560)         0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2390)         22850790    dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2447)         0           dense_12[0][0]                   \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 2447)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 597)          1461456     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 597)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2390)         1429220     dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 2390)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 9560)         22857960    dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,599,426\n",
      "Trainable params: 48,599,426\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 190 steps, validate on 4067 samples\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 5s 24ms/step - loss: 27.6741 - mse_masked: 18.9048 - mape_masked: 0.9899 - mae_masked: 0.0016 - val_loss: 26.6158 - val_mse_masked: 18.5400 - val_mape_masked: 0.9806 - val_mae_masked: 0.0016\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 4s 20ms/step - loss: 23.9929 - mse_masked: 16.4415 - mape_masked: 0.9075 - mae_masked: 0.0015 - val_loss: 19.8774 - val_mse_masked: 12.8032 - val_mape_masked: 0.7631 - val_mae_masked: 0.0012\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 4s 19ms/step - loss: 15.4771 - mse_masked: 8.7698 - mape_masked: 0.4830 - mae_masked: 9.5958e-04 - val_loss: 13.1113 - val_mse_masked: 6.7430 - val_mape_masked: 0.3188 - val_mae_masked: 7.8532e-04\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 4s 19ms/step - loss: 11.4721 - mse_masked: 5.3892 - mape_masked: 0.2025 - mae_masked: 6.8905e-04 - val_loss: 11.0372 - val_mse_masked: 5.2112 - val_mape_masked: 0.1829 - val_mae_masked: 6.5306e-04\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 4s 20ms/step - loss: 9.7289 - mse_masked: 4.1268 - mape_masked: 0.1020 - mae_masked: 5.8583e-04 - val_loss: 9.9479 - val_mse_masked: 4.5439 - val_mape_masked: 0.1348 - val_mae_masked: 6.0156e-04\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 4s 20ms/step - loss: 8.7244 - mse_masked: 3.4973 - mape_masked: 0.0614 - mae_masked: 5.3544e-04 - val_loss: 9.2358 - val_mse_masked: 4.1615 - val_mape_masked: 0.0888 - val_mae_masked: 5.6480e-04\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 4s 20ms/step - loss: 7.9597 - mse_masked: 3.0270 - mape_masked: 0.0220 - mae_masked: 4.9739e-04 - val_loss: 8.6595 - val_mse_masked: 3.8445 - val_mape_masked: 0.0625 - val_mae_masked: 5.3886e-04\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 4s 19ms/step - loss: 7.3521 - mse_masked: 2.6521 - mape_masked: -0.0015 - mae_masked: 4.6412e-04 - val_loss: 8.2538 - val_mse_masked: 3.6453 - val_mape_masked: 0.0469 - val_mae_masked: 5.2263e-04\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 4s 19ms/step - loss: 6.9516 - mse_masked: 2.4366 - mape_masked: -0.0143 - mae_masked: 4.4689e-04 - val_loss: 7.9397 - val_mse_masked: 3.4953 - val_mape_masked: 0.0250 - val_mae_masked: 5.0631e-04\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 4s 19ms/step - loss: 6.6447 - mse_masked: 2.2777 - mape_masked: -0.0301 - mae_masked: 4.3253e-04 - val_loss: 7.6765 - val_mse_masked: 3.3652 - val_mape_masked: 0.0171 - val_mae_masked: 4.9566e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "steps_per_epoch = Xr_train.shape[0] // batch_size\n",
    "\n",
    "deep_autorec_multi = build_autorec_multi_input2(user_item_matrix.shape[1], features_matrix.shape[1])\n",
    "results_autorec_multi = deep_autorec_multi.fit_generator(\n",
    "    generator_ratings_features(Xr_train, Xf_train, batch_size), \n",
    "    epochs=10,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=([Xr_val.toarray().astype(np.float32), Xf_val], Xr_val.toarray().astype(np.float32))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:25:55.384168Z",
     "start_time": "2020-01-29T10:25:54.854566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9584022"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xr_test_reconstruction_multi = deep_autorec_multi.predict([Xr_test_pred_hidden.toarray(), Xf_test])\n",
    "mse_masked(Xr_test_pred_hidden.toarray(), Xr_test_reconstruction_multi).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:25:57.647163Z",
     "start_time": "2020-01-29T10:25:57.632648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5427463, 0.012227664, 1.4799496)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_multi = []\n",
    "for test_uid, test_itemid in zip(test_uids, test_item_ids):\n",
    "    yhat_multi.append(Xr_test_reconstruction_multi[test_uid, test_itemid])\n",
    "    \n",
    "mse_masked(test_y, yhat_multi).numpy(), mape_masked(test_y, yhat_multi).numpy(), mae_masked(test_y, yhat_multi).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:25:59.907560Z",
     "start_time": "2020-01-29T10:25:59.898403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3.707496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3.352658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.824492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.861844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5.124014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5</td>\n",
       "      <td>4.234419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4</td>\n",
       "      <td>3.796869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5</td>\n",
       "      <td>1.594608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>2.677118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5</td>\n",
       "      <td>4.201627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y      yhat\n",
       "0    4  3.707496\n",
       "1    5  3.352658\n",
       "2    4  3.824492\n",
       "3    5  3.861844\n",
       "4    2  5.124014\n",
       "..  ..       ...\n",
       "119  5  4.234419\n",
       "120  4  3.796869\n",
       "121  5  1.594608\n",
       "122  3  2.677118\n",
       "123  5  4.201627\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'y': test_y, 'yhat': yhat_multi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:26:02.428851Z",
     "start_time": "2020-01-29T10:26:02.423924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0414206115887032"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(test_y, yhat_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:26:04.807735Z",
     "start_time": "2020-01-29T10:26:04.689289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5f51d156d8>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_y, yhat_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:27:33.323953Z",
     "start_time": "2020-01-29T10:27:33.129397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28473"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "recommendation_engine_test",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyterenvf",
   "language": "python",
   "name": "jupyterenvf"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
